Please look at estimateMixprop.m and test.m. Should be enough to get started.
	Note that some manual intervention is suggested for the code. To elaborate, we use a grid of alpha (class priors) values between 0 and 1. When I use the code I generally set it to 0.001:0.001:0.999 (the default is 0.01, 0.02, ... 0.99). The code will run and calculate the likelihood for each of these points. Next, we have a univariate transform built-in, which is actually a predictor between positive and unlabeled data. Using an ensemble of neural networks is best here. We hardcoded 100 classifiers and that each such net has 5 hidden neurons. However, if you use more networks and more hidden neurons and get a higher AUC of the classification model, you should use those results for alphamax. Finally, once the 1000 data points are plotted, we run an inflection script to identify a point of the sharpest transition. That algorithm is not perfect and I would recommend a manual inspection of the results when you get an output.
	Because we use a window-based approach there (with +/- 3 points from a center) this script does not work well when alpha* is very low or very high. In these cases, the inflection script might give you a random proportion, so you need to correct manually. In practice, we generally would set such estimated to 0.001 or 0.0001 depending on what the first point in the grid (above) is.

